# ОТЧЕТ ПО РАБОТЕ

## Классификация пород собак с использованием Vision Transformer на Stanford Dogs Dataset

---

## 1. Постановка задачи, Цель работы. Теоретическая база

### 1.1. Постановка задачи

Задача заключается в разработке и исследовании системы классификации пород собак на основе изображений из Stanford Dogs Dataset. Датасет содержит 20,580 изображений 120 различных пород собак, что представляет собой задачу многоклассовой классификации с большим количеством классов.

### 1.2. Цель работы

Основной целью работы является:

1. Разработка системы классификации пород собак с использованием архитектуры Vision Transformer (ViT)
2. Сравнение эффективности различных подходов к обучению:
   - Дообучение предобученной модели
   - Обучение модели с нуля
3. Исследование влияния различных оптимизаторов (Adam, SPAM) на качество классификации
4. Оценка производительности модели по метрикам Accuracy, Precision, Recall и F1-score

### 1.3. Теоретическая база

#### Vision Transformer (ViT)

Vision Transformer — это архитектура глубокого обучения, которая применяет механизм внимания (attention) из области обработки естественного языка к задачам компьютерного зрения. Основные принципы:

1. **Разбиение изображения на патчи**: Входное изображение размером 224×224 пикселей разбивается на непересекающиеся патчи размером 16×16 пикселей, что дает 196 патчей.

2. **Линейная проекция патчей**: Каждый патч преобразуется в вектор фиксированной размерности (embedding) через линейный слой.

3. **Добавление позиционных энкодингов**: К каждому патчу добавляется информация о его позиции в исходном изображении.

4. **Transformer Encoder**: Последовательность патчей обрабатывается стандартным Transformer-энкодером, который состоит из:
   - Multi-Head Self-Attention механизмов
   - Feed-Forward Networks
   - Layer Normalization
   - Residual connections

5. **Классификационный токен [CLS]**: Специальный токен добавляется в начало последовательности и используется для финальной классификации.

#### Преимущества ViT:

- **Глобальное внимание**: Модель может учитывать связи между любыми частями изображения
- **Масштабируемость**: Производительность улучшается с увеличением размера модели и объема данных
- **Переносимость**: Предобученные модели можно эффективно дообучать на новых задачах

#### Оптимизаторы

**Adam (Adaptive Moment Estimation)**:
- Адаптивный алгоритм оптимизации, который вычисляет индивидуальные скорости обучения для каждого параметра
- Использует скользящие средние градиентов (momentum) и их квадратов
- Хорошо работает для большинства задач глубокого обучения

**SPAM (Spike-Aware Adam with Momentum Reset)**:
- Модификация Adam с периодическим сбросом момента (momentum reset)
- Включает механизм обнаружения "спайков" в градиентах
- Применяет адаптивное обрезание градиентов относительно экспоненциально взвешенного среднего квадратов градиентов
- Имеет встроенный warmup механизм

---

## 2. Описание разработанной системы

### 2.1. Архитектура системы

Система состоит из следующих компонентов:

```
┌─────────────────────────────────────────────────────────────┐
│                    СИСТЕМА КЛАССИФИКАЦИИ                    │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐  │
│  │   Загрузка   │───▶│ Предобработка│───▶│   ViT Model  │  │
│  │   данных     │    │  изображений │    │              │  │
│  └──────────────┘    └──────────────┘    └──────────────┘  │
│                                                              │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐  │
│  │   Обучение   │───▶│  Валидация   │───▶│   Тестирование│  │
│  │   модели     │    │              │    │              │  │
│  └──────────────┘    └──────────────┘    └──────────────┘  │
│                                                              │
│  ┌──────────────┐    ┌──────────────┐                      │
│  │  Оптимизатор │    │   Метрики    │                      │
│  │ (Adam/SPAM)  │    │  (Acc/Prec/  │                      │
│  │              │    │  Rec/F1)     │                      │
│  └──────────────┘    └──────────────┘                      │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### 2.2. Архитектура модели Vision Transformer

Модель использует следующую конфигурацию:

- **Размер входного изображения**: 224×224 пикселей
- **Размер патча**: 16×16 пикселей (14×14 патчей)
- **Размерность скрытого слоя (hidden size)**: 768
- **Количество слоев Transformer**: 12
- **Количество голов внимания**: 12
- **Размер промежуточного слоя**: 3072
- **Количество классов**: 120 (породы собак)

#### Структура модели:

```
Input Image (224×224×3)
    │
    ▼
Patch Embedding (196 patches × 768)
    │
    ▼
[CLS] Token + Positional Encoding
    │
    ▼
Transformer Encoder × 12
    ├─ Multi-Head Self-Attention (12 heads)
    ├─ Feed-Forward Network
    └─ Layer Normalization
    │
    ▼
[CLS] Token Representation (768)
    │
    ▼
Classifier Head (768 → 120)
    │
    ▼
Output Logits (120 classes)
```

### 2.3. Алгоритмы и принципы работы

#### 2.3.1. Предобработка данных

**Для обучающей выборки:**
- Изменение размера до 224×224
- Случайное горизонтальное отражение (вероятность 0.5)
- Случайный поворот на ±10 градусов
- Изменение яркости и контраста (±20%)
- Нормализация по средним значениям ImageNet: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]

**Для валидационной и тестовой выборок:**
- Изменение размера до 224×224
- Нормализация по средним значениям ImageNet

#### 2.3.2. Процесс обучения

1. **Инициализация модели**:
   - Вариант 1: Загрузка предобученной модели `google/vit-base-patch16-224` из Hugging Face
   - Вариант 2: Инициализация случайными весами

2. **Forward pass**:
   - Изображение разбивается на патчи
   - Патчи проецируются в пространство embeddings
   - Добавляются позиционные энкодинги
   - Данные проходят через Transformer-энкодер
   - Используется [CLS] токен для получения представления изображения
   - Классификационная голова выдает логиты для 120 классов

3. **Вычисление функции потерь**:
   - Используется CrossEntropyLoss
   - Для mixed precision training применяется автоматическое масштабирование градиентов

4. **Backward pass и оптимизация**:
   - Вычисление градиентов
   - Обновление весов с помощью выбранного оптимизатора (Adam или SPAM)
   - Для Adam: применение ReduceLROnPlateau scheduler при застое валидационной метрики

#### 2.3.3. Разделение данных

Датасет разделен на три части:
- **Обучающая выборка**: 70% (14,355 изображений)
- **Валидационная выборка**: 15% (3,025 изображений)
- **Тестовая выборка**: 15% (3,200 изображений)

Разделение выполнено с сохранением пропорций классов (стратифицированное разделение).

#### 2.3.4. Метрики оценки

Система оценивается по следующим метрикам:

- **Accuracy**: Доля правильно классифицированных изображений
- **Precision** (macro-averaged): Средняя точность по всем классам
- **Recall** (macro-averaged): Средняя полнота по всем классам
- **F1-score** (macro-averaged): Гармоническое среднее Precision и Recall

### 2.4. Технические детали реализации

#### Используемые технологии:

- **PyTorch 2.9.0+ (CUDA 12.1)**: Фреймворк для глубокого обучения с поддержкой GPU
- **Hugging Face Transformers 4.30.0+**: Библиотека для работы с предобученными моделями ViT
- **Torchvision 0.15.0+**: Утилиты для работы с изображениями и трансформациями
- **scikit-learn 1.3.0+**: Метрики оценки качества (accuracy, precision, recall, F1-score)
- **Mixed Precision Training (AMP)**: Ускорение обучения на GPU с использованием bfloat16/float16
- **SPAM Optimizer**: Локальная реализация оптимизатора Spike-Aware Adam with Momentum Reset

#### Конфигурация оборудования:

- **GPU**: NVIDIA GeForce RTX 3060 Ti (12GB VRAM)
- **CUDA Version**: 12.1 (совместимо с драйвером CUDA 13.0)
- **Операционная система**: Windows 10/11
- **Python**: 3.11+

#### Структура кода:

**model.py**:
- Класс `VisionTransformer`: Реализация модели ViT с поддержкой предобученных весов
- Класс `DogDataset`: Датасет для загрузки и предобработки изображений
- Функция `get_transforms`: Трансформации для train/val/test сплитов

**train.py**:
- Функция `train_epoch`: Обучение модели на одной эпохе с поддержкой AMP
- Функция `validate`: Валидация модели
- Функция `test`: Тестирование модели на тестовой выборке
- Функция `main`: Основной цикл обучения с поддержкой различных оптимизаторов

**galore_torch/SPAM.py**:
- Класс `CosineDecay`: Косинусное затухание для warmup
- Класс `AdamW` (экспортируется как `SPAM`): Реализация SPAM оптимизатора
  - Метод `step()`: Выполнение одного шага оптимизации
  - Метод `init_masks()`: Инициализация масок (не используется в текущей реализации)
  - Метод `update_masks()`: Обновление масок при reset (не используется)
  - Spike-aware gradient clipping: Обрезание градиентов при обнаружении "шипов"
  - Momentum reset: Периодический сброс momentum каждые `DeltaT` шагов

#### Оптимизации производительности:

1. **Mixed Precision Training (AMP)**: 
   - Использование автоматического смешанного формата (bfloat16/float16) для ускорения обучения на GPU
   - Автоматическое масштабирование градиентов через `torch.amp.GradScaler`
   - Ускорение обучения в 1.5-2 раза при сохранении точности
   - Снижение использования памяти GPU примерно в 2 раза

2. **DataLoader оптимизации**:
   - `pin_memory=True` для быстрой передачи данных на GPU (только для CUDA)
   - `num_workers=2` для Windows, `num_workers=4` для Linux (параллельная загрузка данных)
   - `prefetch_factor=2` для предзагрузки батчей
   - `persistent_workers=False` для Windows (избежание проблем с памятью)
   - `non_blocking=True` для асинхронной передачи данных на GPU

3. **Оптимизация для GPU (RTX 3060 Ti 12GB)**:
   - Автоматический выбор batch size: 64 для GPU, 32 для CPU
   - Автоматическое определение устройства (CUDA/CPU)
   - Оптимизированные настройки для Windows (меньше workers для избежания проблем с памятью)

#### Интеграция SPAM оптимизатора:

SPAM (Spike-Aware Adam with Momentum Reset) интегрирован в систему следующим образом:

1. **Локальная реализация**: 
   - Модуль `galore_torch/SPAM.py` содержит полную реализацию оптимизатора
   - Скопирован из репозитория `TianjinYellow/SPAM-Optimizer`
   - Экспортируется через `galore_torch/__init__.py` как `SPAM`

2. **Параметры SPAM**:
   - `lr`: Learning rate (из аргументов командной строки, по умолчанию 1e-3)
   - `warmup_steps=150`: Количество шагов для warmup после reset momentum
   - `threshold=5000`: Порог для spike-aware gradient clipping
   - `DeltaT=500`: Период сброса momentum (каждые 500 шагов)
   - `betas=(0.9, 0.999)`: Коэффициенты для экспоненциального скользящего среднего
   - `weight_decay=0.0`: По умолчанию отключен (можно добавить)

3. **Особенности реализации**:
   - Работает без разреженных масок (`density` не используется) для совместимости с 1D параметрами (bias, векторы)
   - Применяет spike-aware clipping: обрезает градиенты, которые превышают порог относительно EMA квадратов градиентов
   - Периодически сбрасывает momentum каждые `DeltaT` шагов для стабилизации обучения
   - Использует внутренний warmup механизм через `CosineDecay` после каждого reset

4. **Использование в коде**:
```python
# Создание SPAM оптимизатора
param_groups = [{'params': model.parameters()}]
optimizer = SPAM(
    param_groups,
    lr=args.lr,
    warmup_steps=150,
    threshold=5000,
    DeltaT=500,
)

# Обучение (стандартный цикл PyTorch)
for epoch in range(epochs):
    for batch in dataloader:
        loss.backward()
        optimizer.step()  # SPAM применяет свои алгоритмы внутри
```

5. **Отличия от стандартного Adam**:
   - SPAM имеет встроенный механизм обнаружения и обработки градиентных "шипов"
   - Периодический сброс momentum для предотвращения накопления ошибок
   - Специальный warmup механизм после каждого reset
   - Не требует внешнего learning rate scheduler (имеет свой внутренний warmup)

---

## 3. Результаты работы и тестирования системы

### 3.1. Проведенные эксперименты

Было проведено три основных эксперимента:

#### Эксперимент 1: Дообучение предобученной модели с Adam
- **Предобученная модель**: Да (google/vit-base-patch16-224)
- **Оптимизатор**: Adam
- **Learning rate**: 1e-4
- **Количество эпох**: 10
- **Batch size**: 32
- **Mixed Precision**: Включен

#### Эксперимент 2: Обучение модели с нуля с Adam
- **Предобученная модель**: Нет
- **Оптимизатор**: Adam
- **Learning rate**: 1e-4
- **Количество эпох**: 15
- **Batch size**: 32
- **Mixed Precision**: Включен

#### Эксперимент 3: Дообучение предобученной модели с SPAM
- **Предобученная модель**: Да (google/vit-base-patch16-224)
- **Оптимизатор**: SPAM (Spike-Aware Adam with Momentum Reset)
- **Learning rate**: 1e-3
- **Количество эпох**: 10
- **Batch size**: 32
- **Mixed Precision**: Включен

### 3.2. Результаты экспериментов

#### Таблица сравнения результатов

| Эксперимент | Предобученная | Оптимизатор | Epochs | LR | Test Accuracy | Test Precision | Test Recall | Test F1 | Best Val Acc |
|-------------|---------------|-------------|--------|----|---------------|----------------|-------------|---------|--------------|
| Adam (pretrained) | Да | ADAM | 10 | 0.0001 | **0.8244** | **0.8294** | **0.8194** | **0.8198** | **0.8420** |
| Adam (scratch) | Нет | ADAM | 15 | 0.0001 | 0.1037 | 0.1120 | 0.1006 | 0.0817 | 0.1098 |
| SPAM (pretrained) | Да | SPAM | 10 | 0.0010 | 0.0566 | 0.0418 | 0.0518 | 0.0352 | 0.0684 |

#### Детальные результаты по экспериментам

**Эксперимент 1: Adam с предобученной моделью (ЛУЧШИЙ РЕЗУЛЬТАТ)**

Тестовые метрики:
- Accuracy: **0.8244** (82.44%)
- Precision: **0.8294** (82.94%)
- Recall: **0.8194** (81.94%)
- F1-score: **0.8198** (81.98%)
- Лучшая валидационная Accuracy: **0.8420** (84.20%)

Динамика обучения:
- Эпоха 1: Train Acc = 0.6876, Val Acc = 0.8139
- Эпоха 5: Train Acc = 0.9522, Val Acc = 0.8083
- Эпоха 8: Train Acc = 0.9937, Val Acc = 0.8420 (лучшая)
- Эпоха 10: Train Acc = 0.9916, Val Acc = 0.8205

**Эксперимент 2: Adam с нуля**

Тестовые метрики:
- Accuracy: 0.1037 (10.37%)
- Precision: 0.1120 (11.20%)
- Recall: 0.1006 (10.06%)
- F1-score: 0.0817 (8.17%)
- Лучшая валидационная Accuracy: 0.1098 (10.98%)

Динамика обучения:
- Эпоха 1: Train Acc = 0.0116, Val Acc = 0.0169
- Эпоха 10: Train Acc = 0.0920, Val Acc = 0.0863
- Эпоха 15: Train Acc = 0.1393, Val Acc = 0.1098 (лучшая)

**Эксперимент 3: SPAM с предобученной моделью**

Тестовые метрики:
- Accuracy: 0.0566 (5.66%)
- Precision: 0.0418 (4.18%)
- Recall: 0.0518 (5.18%)
- F1-score: 0.0352 (3.52%)
- Лучшая валидационная Accuracy: 0.0684 (6.84%)

Динамика обучения:
- Эпоха 1: Train Acc = 0.0112, Val Acc = 0.0136
- Эпоха 5: Train Acc = 0.0371, Val Acc = 0.0367
- Эпоха 10: Train Acc = 0.0566, Val Acc = 0.0684 (лучшая)

### 3.3. Сравнительный анализ

#### Сравнение предобученных моделей vs обучение с нуля

| Метрика | Предобученная (среднее) | С нуля | Разница |
|---------|------------------------|--------|---------|
| Accuracy | 0.4405 | 0.1037 | **+0.3367** |
| Precision | 0.4356 | 0.1120 | **+0.3236** |
| Recall | 0.4356 | 0.1006 | **+0.3350** |
| F1-score | 0.4275 | 0.0817 | **+0.3459** |

**Вывод**: Использование предобученной модели дает значительное преимущество (более чем в 4 раза по метрике F1-score).

#### Сравнение оптимизаторов (на предобученной модели)

| Метрика | Adam | SPAM | Преимущество |
|---------|------|------|--------------|
| Accuracy | **0.8244** | 0.0566 | Adam: **+0.7678** |
| Precision | **0.8294** | 0.0418 | Adam: **+0.7876** |
| Recall | **0.8194** | 0.0518 | Adam: **+0.7676** |
| F1-score | **0.8198** | 0.0352 | Adam: **+0.7846** |

**Вывод**: Оптимизатор Adam показал значительно лучшие результаты по сравнению с SPAM на данной задаче. 

**Анализ результатов SPAM**:
SPAM оптимизатор показал очень низкие результаты (Accuracy ~5.66%), что значительно хуже даже случайного угадывания (1/120 ≈ 0.83%). Возможные причины:

1. **Несовместимость с архитектурой ViT**: SPAM был разработан специально для обучения больших языковых моделей (LLM), где градиентные "шипы" являются частой проблемой. Архитектура ViT и характер градиентов могут отличаться от LLM.

2. **Неоптимальные гиперпараметры**: 
   - `threshold=5000` может быть слишком высоким для данной задачи
   - `DeltaT=500` может быть слишком частым сбросом momentum
   - `warmup_steps=150` может быть недостаточным

3. **Недостаточное количество эпох**: SPAM может требовать больше эпох для стабилизации, особенно учитывая периодические resets momentum.

4. **Отсутствие разреженных масок**: В текущей реализации SPAM работает без масок (`density`), что может снижать его эффективность, так как некоторые оптимизации SPAM рассчитаны на работу с разреженными обновлениями.

5. **Особенности задачи**: Классификация изображений может иметь другой характер градиентов по сравнению с языковым моделированием, для которого SPAM был разработан.

### 3.4. Лучшие результаты

**Лучшая модель по всем метрикам**: Adam с предобученной моделью

- **Лучшая Accuracy**: 0.8244 (82.44%)
- **Лучшая Precision**: 0.8294 (82.94%)
- **Лучшая Recall**: 0.8194 (81.94%)
- **Лучшая F1-score**: 0.8198 (81.98%)

### 3.5. Анализ кривых обучения

#### Эксперимент 1 (Adam, предобученная модель):
- **Быстрая сходимость**: Уже на первой эпохе достигнута валидационная accuracy 0.8139
- **Стабильное обучение**: Метрики продолжают улучшаться до 8-й эпохи
- **Небольшое переобучение**: После 8-й эпохи валидационная метрика начинает снижаться, хотя обучающая продолжает расти

#### Эксперимент 2 (Adam, с нуля):
- **Медленная сходимость**: Модель обучается очень медленно, достигая только 10.37% accuracy после 15 эпох
- **Недостаточное обучение**: Для обучения с нуля требуется значительно больше эпох и данных

#### Эксперимент 3 (SPAM, предобученная модель):
- **Проблемы со сходимостью**: Модель практически не обучается, оставаясь на уровне случайного угадывания
- **Возможные причины**: Неправильная настройка гиперпараметров SPAM или несовместимость с архитектурой ViT

---

## 4. Выводы по работе

### 4.1. Основные достижения

1. **Успешно разработана система классификации пород собак** на основе Vision Transformer, достигшая точности **82.44%** на тестовой выборке.

2. **Проведено сравнительное исследование** различных подходов к обучению:
   - Дообучение предобученной модели показало превосходство над обучением с нуля
   - Оптимизатор Adam оказался значительно эффективнее SPAM для данной задачи

3. **Реализована полная инфраструктура** для обучения, валидации и тестирования моделей с поддержкой:
   - Mixed Precision Training для ускорения
   - Автоматического сохранения лучших моделей
   - Детального логирования метрик

### 4.2. Ключевые выводы

1. **Эффективность предобученных моделей**: Использование предобученной ViT модели из Hugging Face дает преимущество более чем в 4 раза по сравнению с обучением с нуля. Это подтверждает важность transfer learning для задач с ограниченным объемом данных.

2. **Выбор оптимизатора**: Стандартный оптимизатор Adam с learning rate 1e-4 показал отличные результаты для дообучения предобученной модели. SPAM оптимизатор не показал ожидаемых результатов, возможно, требуя дополнительной настройки или большего количества эпох.

3. **Архитектура ViT**: Vision Transformer успешно справляется с задачей классификации пород собак, демонстрируя способность извлекать глобальные паттерны из изображений через механизм внимания.

4. **Недостаточность данных для обучения с нуля**: Обучение ViT с нуля требует значительно большего объема данных и вычислительных ресурсов. При текущем размере датасета (14,355 обучающих изображений для 120 классов) обучение с нуля неэффективно.

### 4.3. Ограничения и проблемы

1. **Неудачный эксперимент с SPAM**: Оптимизатор SPAM не показал ожидаемых результатов. Возможные причины:
   - Неправильная настройка гиперпараметров (warmup_steps, threshold, DeltaT)
   - Несовместимость с архитектурой ViT
   - Недостаточное количество эпох для срабатывания механизма momentum reset

2. **Переобучение**: В лучшей модели наблюдается небольшое переобучение после 8-й эпохи, что можно улучшить с помощью:
   - Ранней остановки (early stopping)
   - Увеличения dropout
   - Более агрессивной аугментации данных

3. **Классовый дисбаланс**: Не исследовалось влияние возможного дисбаланса классов в датасете на качество классификации.

### 4.4. Рекомендации для дальнейшей работы

1. **Улучшение качества модели**:
   - Применение техник регуляризации (dropout, weight decay)
   - Использование более агрессивных аугментаций данных
   - Применение техник fine-tuning (замораживание части слоев)
   - Эксперименты с различными learning rate schedules

2. **Исследование SPAM оптимизатора**:
   - Детальная настройка гиперпараметров (threshold, DeltaT, warmup_steps)
   - Увеличение количества эпох до 20-30 для стабилизации
   - Исследование влияния различных значений warmup_steps и DeltaT
   - Эксперименты с включением разреженных масок для совместимых параметров
   - Анализ градиентов для понимания характера "шипов" в данной задаче
   - Сравнение SPAM с другими адаптивными оптимизаторами (AdamW, RAdam)

3. **Расширение экспериментов**:
   - Тестирование других оптимизаторов (AdamW, SGD с momentum)
   - Эксперименты с различными размерами моделей ViT
   - Исследование влияния размера патчей на качество

4. **Анализ ошибок**:
   - Визуализация confusion matrix
   - Анализ наиболее часто путаемых пород
   - Исследование влияния различных характеристик изображений на качество классификации

---

## 5. Использованные источники

### 5.1. Научные статьи и публикации

1. **Dosovitskiy, A., et al.** (2020). "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale." *arXiv preprint arXiv:2010.11929*.  
   Основополагающая работа по применению Transformer архитектуры к задачам компьютерного зрения.

2. **Vaswani, A., et al.** (2017). "Attention is All You Need." *Advances in Neural Information Processing Systems 30 (NIPS 2017)*.  
   Оригинальная статья о механизме внимания и архитектуре Transformer.

3. **Stanford Dogs Dataset**:  
   Khosla, A., Jayadevaprakash, N., Yao, B., & Li, F. F. (2011). "Novel dataset for Fine-Grained Image Categorization." *First Workshop on Fine-Grained Visual Categorization, IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*.

### 5.2. Библиотеки и фреймворки

1. **PyTorch**:  
   Paszke, A., et al. (2019). "PyTorch: An Imperative Style, High-Performance Deep Learning Library." *Advances in Neural Information Processing Systems 32*.

2. **Hugging Face Transformers**:  
   Wolf, T., et al. (2020). "Transformers: State-of-the-Art Natural Language Processing." *Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations*.

3. **scikit-learn**:  
   Pedregosa, F., et al. (2011). "Scikit-learn: Machine Learning in Python." *Journal of Machine Learning Research 12*.

### 5.3. Документация и ресурсы

1. **PyTorch Documentation**: https://pytorch.org/docs/stable/index.html

2. **Hugging Face Transformers Documentation**: https://huggingface.co/docs/transformers/

3. **Vision Transformer (ViT) Model Card**: https://huggingface.co/google/vit-base-patch16-224

4. **Stanford Dogs Dataset**: http://vision.stanford.edu/aditya86/ImageNetDogs/

5. **SPAM Optimizer**:  
   TianjinYellow/SPAM-Optimizer (GitHub repository)  
   Оптимизатор Spike-Aware Adam with Momentum Reset  
   Luo, L., et al. (2025). "SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training." *arXiv preprint arXiv:2501.06842*.

### 5.4. Дополнительные материалы

1. **Mixed Precision Training**:  
   Micikevicius, P., et al. (2018). "Mixed Precision Training." *arXiv preprint arXiv:1710.03740*.

2. **Transfer Learning**:  
   Yosinski, J., et al. (2014). "How transferable are features in deep neural networks?" *Advances in Neural Information Processing Systems 27*.

---

## Приложения

### Приложение A: Структура проекта

```
aidog/
├── archive/                    # Датасет Stanford Dogs
│   ├── images/
│   │   ├── Images/            # Исходные изображения
│   │   ├── train/             # Обучающая выборка (70%)
│   │   ├── val/               # Валидационная выборка (15%)
│   │   └── test/              # Тестовая выборка (15%)
│   └── annotations/
│       └── Annotation/        # Исходные аннотации
├── checkpoints/               # Сохраненные модели и результаты
│   ├── best_model_*.pth       # Веса лучших моделей
│   └── results_*.json         # Метрики экспериментов
├── galore_torch/              # Реализация SPAM оптимизатора
├── model.py                   # Архитектура Vision Transformer
├── train.py                   # Скрипт обучения
├── split_dataset.py           # Разделение датасета
├── compare_results.py         # Сравнение результатов
├── run_experiments.py         # Автоматический запуск экспериментов
├── requirements.txt           # Зависимости проекта
└── README.md                  # Документация проекта
```

### Приложение B: Команды для воспроизведения результатов

#### Установка и настройка:

```bash
# 1. Создание виртуального окружения (рекомендуется)
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# 2. Установка PyTorch с поддержкой CUDA (для GPU)
# Для CUDA 12.1 (совместимо с CUDA 13.0):
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 3. Установка остальных зависимостей
pip install -r requirements.txt

# 4. Проверка установки CUDA
python -c "import torch; print('CUDA available:', torch.cuda.is_available()); print('GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A')"
```

#### Запуск экспериментов:

```bash
# 1. Разделение датасета (если еще не выполнено)
python split_dataset.py

# 2. Эксперимент 1: Adam с предобученной моделью (ЛУЧШИЙ РЕЗУЛЬТАТ)
python train.py --pretrained --optimizer adam --epochs 10 --lr 1e-4 --batch_size 32

# 3. Эксперимент 2: Adam с нуля
python train.py --optimizer adam --epochs 15 --lr 1e-4 --batch_size 32

# 4. Эксперимент 3: SPAM с предобученной моделью
python train.py --pretrained --optimizer spam --epochs 10 --lr 1e-3 --batch_size 32

# 5. Автоматический запуск всех экспериментов
python run_experiments.py

# 6. Сравнение результатов
python compare_results.py
```

#### Дополнительные параметры:

```bash
# Использование большего batch size для GPU (автоматически 64)
python train.py --pretrained --optimizer adam --epochs 10 --lr 1e-4

# Отключение Mixed Precision (не рекомендуется для GPU)
python train.py --pretrained --optimizer adam --epochs 10 --lr 1e-4 --no_amp

# Указание количества workers для DataLoader
python train.py --pretrained --optimizer adam --epochs 10 --lr 1e-4 --num_workers 4

# Обучение на CPU (автоматически batch_size=32, num_workers=0)
# (требует установки CPU версии PyTorch)
python train.py --pretrained --optimizer adam --epochs 10 --lr 1e-4
```

#### Примечания:

- **Для GPU**: Mixed Precision автоматически включен, batch_size по умолчанию 64
- **Для CPU**: Mixed Precision отключен, batch_size по умолчанию 32, num_workers=0
- **Windows**: Автоматически используется меньше workers (2 вместо 4) для избежания проблем с памятью
- Все результаты сохраняются в `checkpoints/`:
  - `best_model_*.pth` - веса лучших моделей
  - `results_*.json` - метрики и история обучения

### Приложение C: Технические характеристики системы

#### Производительность обучения:

**Эксперимент 1 (Adam, предобученная модель, GPU RTX 3060 Ti)**:
- Время на эпоху: ~3-4 минуты (train + validation)
- Скорость: ~2.5-3.0 итераций/сек
- Использование памяти GPU: ~4-6 GB (с Mixed Precision)
- Общее время обучения (10 эпох): ~35-40 минут

**Эксперимент 2 (Adam, с нуля, GPU RTX 3060 Ti)**:
- Время на эпоху: ~3-4 минуты
- Скорость: ~2.5-3.0 итераций/сек
- Использование памяти GPU: ~4-6 GB
- Общее время обучения (15 эпох): ~50-60 минут

**Эксперимент 3 (SPAM, предобученная модель, GPU RTX 3060 Ti)**:
- Время на эпоху: ~3-4 минуты
- Скорость: ~2.5-3.0 итераций/сек
- Использование памяти GPU: ~4-6 GB
- Общее время обучения (10 эпох): ~35-40 минут

#### Оптимизации для GPU:

1. **Mixed Precision Training**:
   - Используется `torch.amp.autocast('cuda')` для автоматического выбора формата
   - Поддержка bfloat16 (если доступно) или float16
   - Автоматическое масштабирование градиентов через `torch.amp.GradScaler('cuda')`

2. **Оптимизация DataLoader**:
   - `pin_memory=True`: Копирование данных в pinned memory для быстрой передачи на GPU
   - `num_workers=2` (Windows) / `num_workers=4` (Linux): Параллельная загрузка данных
   - `prefetch_factor=2`: Предзагрузка следующих батчей
   - `non_blocking=True`: Асинхронная передача данных на GPU

3. **Управление памятью**:
   - Автоматическая очистка кэша CUDA при необходимости
   - Оптимизированные настройки для Windows (меньше workers)

---

**Дата составления отчета**: 2024  
**Автор**: [Ваше имя]  
**Проект**: Классификация пород собак с использованием Vision Transformer

